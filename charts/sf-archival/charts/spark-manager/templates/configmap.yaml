kind: ConfigMap
apiVersion: v1
metadata:
  name: {{ template "spark-manager.fullname" . }}-monitor
  namespace: {{ .Release.Namespace }}
data:
  config.json: |-
    {
      "db": {
        "name":  "{{ .Values.global.postgresql.postgresqlDatabase }}",
        "user":  "{{ .Values.global.postgresql.postgresqlUsername }}",
        "password": "{{ .Values.global.postgresql.postgresqlPassword }}",
        "host": "{{ template "spark-manager.postgresql.fullname" . }}",
        "port": {{ .Values.global.postgresql.servicePort }}
      }
    }

---

kind: ConfigMap
apiVersion: v1
metadata:
  name: {{ template "spark-manager.fullname" . }}-jobserver
  namespace: {{ .Release.Namespace }}
data:
  config.json: |-
    {
      "db": {
        "name":  "{{ .Values.global.postgresql.postgresqlDatabase }}",
        "user":  "{{ .Values.global.postgresql.postgresqlUsername }}",
        "password": "{{ .Values.global.postgresql.postgresqlPassword }}",
        "host": "{{ template "spark-manager.postgresql.fullname" . }}",
        "port": {{ .Values.global.postgresql.servicePort }}
      },
      "serverPort": ":{{ .Values.jobserver.serverPort }}"
    }

---

kind: ConfigMap
apiVersion: v1
metadata:
  name: {{ template "spark-manager.fullname" . }}-infrastructure
  namespace: {{ .Release.Namespace }}
data:
  config.json: |-
    {
      "db": {
        "name":  "{{ .Values.global.postgresql.postgresqlDatabase }}",
        "user":  "{{ .Values.global.postgresql.postgresqlUsername }}",
        "password": "{{ .Values.global.postgresql.postgresqlPassword }}",
        "host": "{{ template "spark-manager.postgresql.fullname" . }}",
        "port": {{ .Values.global.postgresql.servicePort }}
      },
      "infrastructures": [
        {
          "mode": "KUBERNETES",
          "preference": {{ .Values.infrastructure.Kubernetes.preference }},
          "template": {
            "pod_namespace": "{{ .Release.Namespace }}",
            "command": [
              "/opt/spark-3.1.2-bin-hadoop3.2/bin/./spark-submit",
              "--name",
              "__PARAM__name",
              "--master",
              "k8s://kubernetes.default.svc:443",
              "--deploy-mode",
              "cluster",
              "--conf",
              "spark.kubernetes.driver.limit.cores={{ .Values.infrastructure.Kubernetes.jobResources.cpu.limits.driver }}",
              "--conf",
              "spark.kubernetes.executor.limit.cores={{ .Values.infrastructure.Kubernetes.jobResources.cpu.limits.executor }}",
              "--conf",
              "spark.executor.instances={{ .Values.infrastructure.Kubernetes.numExecutors }}",
              "--conf",
              "spark.kubernetes.executor.request.cores={{ .Values.infrastructure.Kubernetes.jobResources.cpu.requests.executor }}",
              "--conf",
              "spark.kubernetes.driver.request.cores={{ .Values.infrastructure.Kubernetes.jobResources.cpu.requests.driver }}",
              "--conf",
              "spark.executor.memory={{ .Values.infrastructure.Kubernetes.jobResources.memory.executor }}",
              "--conf",
              "spark.driver.memory={{ .Values.infrastructure.Kubernetes.jobResources.memory.driver }}",
              "--conf",
              "spark.eventLog.enabled=true",
              "--conf",
{{- if eq .Values.global.secrets.aws.enable true }}
              "spark.eventLog.dir=s3a://{{ index .Values "jobserver" "sparkProperties" "logDirectory" }}",
{{- else if eq .Values.global.secrets.azure.enable true }}
              "spark.eventLog.dir=wasbs://{{ index .Values "jobserver" "sparkProperties" "azureLogContainer" }}@{{ .Values.global.secrets.azure.STORAGE_ACCOUNT_NAME }}.blob.core.windows.net/{{ index .Values "jobserver" "sparkProperties" "azureLogDirectory" }}",
{{- else}}
              "spark.eventLog.dir=gs://{{ index .Values "jobserver" "sparkProperties" "logDirectory" }}",
{{- end }}
              "--conf",
              "spark.kubernetes.driver.annotation.prometheus.io/scrape=false",
              "--conf",
              "spark.kubernetes.driver.label.{{ .Values.global.snappyflowProjectLabel}}={{ .Values.global.snappyflowProjectName }}",
              "--conf",
              "spark.kubernetes.executor.label.{{ .Values.global.snappyflowProjectLabel}}={{ .Values.global.snappyflowProjectName }}",
              "--conf",
              "spark.kubernetes.driver.label.{{ .Values.global.snappyflowAppLabel }}={{ .Values.global.snappyflowAppName }}",
              "--conf",
              "spark.kubernetes.executor.label.{{ .Values.global.snappyflowAppLabel }}={{ .Values.global.snappyflowAppName }}",
              "--conf",
              "spark.kubernetes.driver.label.release={{ .Release.Name }}",
              "--conf",
              "spark.kubernetes.executor.label.release={{ .Release.Name }}",
              "--conf",
              "spark.kubernetes.container.image={{ .Values.compactionImage }}",
              "--conf",
              "spark.kubernetes.container.image.pullSecrets={{ .Values.global.imagePullSecrets }}",
{{- if or (and (eq .Values.global.secrets.aws.enable true) (eq .Values.global.secrets.aws.use_iam_role true)) (and (eq .Values.global.secrets.gcs.enable true) (eq .Values.global.secrets.gcs.use_google_service_account true)) }}
              "--conf",
              "spark.kubernetes.authenticate.driver.serviceAccountName={{ .Release.Name }}-service-account",
              "--conf",
              "spark.kubernetes.authenticate.executor.serviceAccountName={{ .Release.Name }}-service-account",
              "--conf",
              "spark.kubernetes.authenticate.serviceAccountName={{ .Release.Name }}-service-account",
{{- else if (eq .Values.global.secrets.azure.enable true) }}
              "--conf",
              "spark.kubernetes.authenticate.driver.serviceAccountName={{ .Release.Name }}-service-account",
              "--conf",
              "spark.kubernetes.authenticate.executor.serviceAccountName={{ .Release.Name }}-service-account",
              "--conf",
              "spark.kubernetes.authenticate.serviceAccountName={{ .Release.Name }}-service-account",
              "--conf",
              "spark.hadoop.fs.AbstractFileSystem.wasbs.Impl=org.apache.hadoop.fs.azure.wasbs",
              "--conf",
              "spark.hadoop.fs.wasbs.impl=org.apache.hadoop.fs.azure.NativeAzureFileSystem",
              "--conf",
              "spark.hadoop.fs.azure.account.key.{{ .Values.global.secrets.azure.STORAGE_ACCOUNT_NAME }}.blob.core.windows.net={{ .Values.global.secrets.azure.STORAGE_ACCOUNT_ACCESS_KEY }}",
              "--conf",
              "spark.hadoop.fs.azure=org.apache.hadoop.fs.azure.NativeAzureFileSystem",
{{- else }}
              "--conf",
              "spark.kubernetes.driver.secretKeyRef.AWS_ACCESS_KEY_ID={{ .Release.Name }}-aws-secret:key",
              "--conf",
              "spark.kubernetes.driver.secretKeyRef.AWS_SECRET_ACCESS_KEY={{ .Release.Name }}-aws-secret:secret",
              "--conf",
              "spark.kubernetes.executor.secretKeyRef.AWS_ACCESS_KEY_ID={{ .Release.Name }}-aws-secret:key",
              "--conf",
              "spark.kubernetes.executor.secretKeyRef.AWS_SECRET_ACCESS_KEY={{ .Release.Name }}-aws-secret:secret",
{{- end }}
              "--conf",
              "spark.kubernetes.namespace={{ .Release.Namespace }}",
              "--class",
              "sf.org.hadoop.Compact",
              "local:///app/compact-orc-scala-2.12.10.jar",
              "__PARAM__source",
              "__PARAM__segmentFile",
              "__PARAM__destination"
            ]
          }
        }
{{- if .Values.infrastructure.EcsFargate.enabled -}}
        ,{
          "mode": "ECS_FARGATE",
          "preference": {{ .Values.infrastructure.EcsFargate.preference }},
          "template": {
            "command": [
              "/opt/spark/bin/./spark-submit",
              "--name",
              "__PARAM__name",
              "--master",
              "local[{{ .Values.infrastructure.EcsFargate.sparkExecutorResources.numExecutors }}]",
              "--conf",
              "spark.executor.instances={{ .Values.infrastructure.EcsFargate.sparkExecutorResources.numExecutors }}",
              "--conf",
              "spark.executor.memory={{ .Values.infrastructure.EcsFargate.sparkExecutorResources.memory }}",
              "--conf",
              "spark.executor.cores={{ .Values.infrastructure.EcsFargate.sparkExecutorResources.cpu }}",
              "--conf",
              "spark.eventLog.enabled=true",
              "--conf",
              "spark.eventLog.dir=s3a://{{ index .Values "jobserver" "sparkProperties" "logDirectory" }}",
              "--conf",
              "spark.hadoop.fs.s3a.aws.credentials.provider=com.amazonaws.auth.EC2ContainerCredentialsProviderWrapper",
              "--class",
              "sf.org.hadoop.Compact",
              "local:///app/compact-orc-scala-2.12.10.jar",
              "__PARAM__source",
              "__PARAM__segmentFile",
              "__PARAM__destination"
            ],
            "ecs_cluster": "{{ .Values.infrastructure.EcsFargate.cluster }}",
            "container_insights_enabled": {{ .Values.infrastructure.EcsFargate.containerInsightsEnabled }},
            "task_defn_family": "{{ .Values.infrastructure.EcsFargate.cluster }}",
            "task_role": "{{ .Values.infrastructure.EcsFargate.iamRole }}",
            "task_exec_role": "{{ .Values.infrastructure.EcsFargate.iamRole }}",
            "task_resources": {
              "cpu": {{ .Values.infrastructure.EcsFargate.jobResources.cpu }},
              "memory": {{ .Values.infrastructure.EcsFargate.jobResources.memory }}
            },
            "task_subnet": "{{ .Values.infrastructure.EcsFargate.taskSubnet }}",
            "task_security_group": "{{ .Values.infrastructure.EcsFargate.taskSecurityGroup }}",
            "task_image": "{{ .Values.compactionImage }}",
            "compaction_secret_arn": "{{ .Values.infrastructure.EcsFargate.compactionSecretArn }}"
          }
        }
{{- end }}
      ]
    }
