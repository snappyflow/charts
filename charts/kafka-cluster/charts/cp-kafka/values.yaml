# Default values for cp-kafka.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

global:
  sfappname: kafka
  sfprojectname: scale-test
  sfappname_key: snappyflow/appname
  sfprojectname_key: snappyflow/projectname
  
prometheus:

  jmx:
    enabled: true
    image: bitnami/jmx-exporter@sha256
    imageTag: 2b03ed611421c0b58dcd70270fed9209c95a5b72a3f8bab186c2dcf27f974811
    imagePullPolicy: IfNotPresent
    port: 5556

    ## Resources configuration for the JMX exporter container.
    ## See the `resources` documentation above for details.
    resources:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 100m
        memory: 256Mi
  
  ## Prometheus Kafka Exporter: exposes complimentary metrics to JMX Exporter
  kafka:
    enabled: true
    image: snappyflowml/kafka-lag-exporter
    imageTag: latest
    interval: 30s
    port: 9308

    ## Resources configuration for the JMX exporter container.
    ## See the `resources` documentation above for details.
    resources:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 100m
        memory: 256Mi

## ------------------------------------------------------
## Kafka
## ------------------------------------------------------

## Number of Kafka brokers
brokers: 3

## Image Info
## ref: https://hub.docker.com/r/confluentinc/cp-kafka/
image: confluentinc/cp-enterprise-kafka
imageTag: 6.0.1

## Specify a imagePullPolicy
## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
imagePullPolicy: IfNotPresent

## Specify an array of imagePullSecrets.
## Secrets must be manually created in the namespace.
## ref: https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
imagePullSecrets:

## StatefulSet Config
## Start and stop pods in Parallel or OrderedReady (one-by-one.)
## ref: https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#pod-management-policy
podManagementPolicy: OrderedReady

## The StatefulSet Update Strategy which Kafka will use when changes are applied: OnDelete or RollingUpdate
## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
updateStrategy: RollingUpdate

# Security Context
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
# for Kafka container
securityContext: {}
  #  runAsUser: 1000
  #  runAsGroup: 1000

## Kafka Server properties
## ref: https://kafka.apache.org/documentation/#configuration
configurationOverrides:
  "offsets.topic.replication.factor": "3"
  "offsets.commit.timeout.ms": 15000
  "default.replication.factor": 1
  "log.retention.hours": 24
  "auto.create.topics.enable": false
  "log.retention.check.interval.ms": 10000
  "zookeeper.connection.timeout.ms": 18000
  "group.initial.rebalance.delay.ms": 3000
  "message.max.bytes": "15728640"
  "delete.topic.enable": true
  "log.roll.hours": 1
  "quota.window.num": 121
  "quota.window.size.seconds": 1

  ## Options required for external access via NodePort
  ## ref:
  ## - http://kafka.apache.org/documentation/#security_configbroker
  ## - https://cwiki.apache.org/confluence/display/KAFKA/KIP-103%3A+Separation+of+Internal+and+External+traffic
  ##
  ## Advertised listeners will use the firstListenerPort value as it's default unless overridden here.
  ## Setting "advertised.listeners" here appends to "PLAINTEXT://${POD_IP}:9092,"
  # "advertised.listeners": |-
  # EXTERNAL://${HOST_IP}:$((31090 + ${KAFKA_BROKER_ID}))
  "listener.security.protocol.map": |-
   PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT,KCONNECT:SASL_PLAINTEXT

## Additional env variables
customEnv: {}
  # KAFKA_METRIC_REPORTERS: "io.confluent.metrics.reporter.ConfluentMetricsReporter"
  # CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: "localhost:9092"

persistence:
  enabled: true

  ## The size of the PersistentVolume to allocate to each Kafka Pod in the StatefulSet. For
  ## production servers this number should likely be much larger.
  size: 1Gi

  ## Kafka data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: ""

  disksPerBroker: 1

## Kafka JVM Heap Option
heapOptions: "-Xms512M -Xmx512M"

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi

## Custom pod annotations
podAnnotations: {}

## Node labels for pod assignment
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
nodeSelector: {}

## Taints to tolerate on node assignment:
## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
tolerations: []

## Pod scheduling constraints
## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity
affinity: {}

## Monitoring
## Kafka JMX Settings
## ref: https://docs.confluent.io/current/kafka/monitoring.html
jmx:
  port: 5555

nodeport:
  enabled: false
  servicePort: 19092
  firstListenerPort: 31090

## ------------------------------------------------------
## Zookeeper
## ------------------------------------------------------
cp-zookeeper:
  ## If true, install the cp-zookeeper chart alongside cp-kafka
  ## ref: ../cp-zookeeper
  enabled: true
  servers: 3
  persistence:
    enabled: true
    dataDirSize: 5Gi
    dataLogDirSize: 5Gi

  ## If the Zookeeper Chart is disabled a URL and port are required to connect
  url: ""
